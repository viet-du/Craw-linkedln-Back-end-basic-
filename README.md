<<<<<<< HEAD
ï»¿# LinkedIn Candidates Crawler + Backend API

## Tá»•ng quan

Dá»± Ã¡n gá»“m 2 pháº§n chÃ­nh:

- `scraper/` (Python + Selenium): crawl há»“ sÆ¡ LinkedIn, Ä‘áº©y dá»¯ liá»‡u qua Kafka, lÆ°u JSON.
- `backend/` (Node.js + Express): API quáº£n lÃ½ á»©ng viÃªn, xÃ¡c thá»±c JWT, phÃ¢n quyá»n, thá»‘ng kÃª, export dá»¯ liá»‡u.

Háº¡ táº§ng Ä‘i kÃ¨m:

- MongoDB (lÆ°u dá»¯ liá»‡u)
- Redis (cache, rate limit, blacklist token)
- Kafka + Zookeeper (stream vÃ  backup dá»¯ liá»‡u crawler)
- Docker Compose (cháº¡y full stack nhanh)

---

## Kiáº¿n trÃºc nhanh

1. Crawler login LinkedIn vÃ  thu tháº­p profile.
2. Crawler ghi `Data/output.json` vÃ  publish lÃªn Kafka topic `linkedin-profiles`.
3. `scraper/kafka_consumer.py` nháº­n dá»¯ liá»‡u vÃ  backup theo ngÃ y vÃ o `Data/backup_data/profiles_YYYY-MM-DD.json`.
4. Backend import dá»¯ liá»‡u JSON vÃ o MongoDB.
5. Dashboard/API Ä‘á»c tá»« MongoDB (kÃ¨m cache Redis).
=======
# ğŸ”— LinkedIn Candidates Crawler & Backend API - TÃ i Liá»‡u Chi Tiáº¿t Äáº§y Äá»§

**TÃ¡c giáº£:** DÆ° Quá»‘c Viá»‡t  
**NgÃ´n ngá»¯:** Python (Scraper) + Node.js (Backend) + MongoDB + Redis  
**Cáº­p nháº­t:** 19 ThÃ¡ng 2, 2026  
**PhiÃªn báº£n:** 1.1.0  
**Tráº¡ng thÃ¡i:** Production Ready âœ…

---

## ğŸ“š TABLE OF CONTENTS

1. [Tá»•ng Quan Dá»± Ãn](#tá»•ng-quan-dá»±-Ã¡n)
2. [Kiáº¿n TrÃºc Há»‡ Thá»‘ng](#kiáº¿n-trÃºc-há»‡-thá»‘ng)
3. [Tech Stack](#tech-stack)
4. [CÃ i Äáº·t & Khá»Ÿi Äá»™ng](#cÃ i-Ä‘áº·t--khá»Ÿi-Ä‘á»™ng)
5. [Cáº¥u TrÃºc Dá»± Ãn Chi Tiáº¿t](#cáº¥u-trÃºc-dá»±-Ã¡n-chi-tiáº¿t)
6. [Giáº£i ThÃ­ch Tá»«ng File](#giáº£i-thÃ­ch-tá»«ng-file)
7. [Database Schema Chi Tiáº¿t](#database-schema-chi-tiáº¿t)
8. [CÃ¡c Lá»‡nh Kiá»ƒm Tra Data](#cÃ¡c-lá»‡nh-kiá»ƒm-tra-data)
9. [File Data & Tráº¡ng ThÃ¡i](#file-data--tráº¡ng-thÃ¡i)
10. [Troubleshooting](#troubleshooting)
>>>>>>> f87fcc33870f50b93e656a90b8da6e68fde0f4dd

---

## Cáº¥u trÃºc thÆ° má»¥c

<<<<<<< HEAD
```text
linkedlin/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ login.html
â”‚   â”‚   â”œâ”€â”€ dashboard.html
â”‚   â”‚   â”œâ”€â”€ admin.html
â”‚   â”‚   â”œâ”€â”€ authInterceptor.js
â”‚   â”‚   â””â”€â”€ js/chart.umd.min.js
=======
### Má»¥c ÄÃ­ch
XÃ¢y dá»±ng há»‡ thá»‘ng hoÃ n chá»‰nh Ä‘á»ƒ:
- **Thu tháº­p dá»¯ liá»‡u LinkedIn** tá»« há»“ sÆ¡ á»©ng viÃªn (Python Selenium)
- **Quáº£n lÃ½ & lÆ°u trá»¯** dá»¯ liá»‡u táº­p trung (MongoDB)
- **Cung cáº¥p API REST** cho phÃ©p tÃ¬m kiáº¿m, lá»c, xuáº¥t dá»¯ liá»‡u
- **XÃ¡c thá»±c & phÃ¢n quyá»n** ngÆ°á»i dÃ¹ng qua JWT tokens
- **Äáº£m báº£o hiá»‡u nÄƒng** báº±ng Redis caching & rate limiting
- **XÃ¡c thá»±c cháº¥t lÆ°á»£ng** dá»¯ liá»‡u tá»± Ä‘á»™ng
- **Quáº£n lÃ½ há»‡ thá»‘ng** cho admin

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             FRONTEND (HTML/JS/Dashboard)                   â”‚
â”‚          index.html, login.html, dashboard.html            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP/REST (port 3000)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EXPRESS BACKEND (Node.js)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Auth Routes   â”‚  â”‚Candidate     â”‚  â”‚Admin Routes      â”‚  â”‚
â”‚  â”‚-Login/Logout â”‚  â”‚Routes        â”‚  â”‚-User Mgmt        â”‚  â”‚
â”‚  â”‚-Register     â”‚  â”‚-Search       â”‚  â”‚-Audit Log        â”‚  â”‚
â”‚  â”‚-Refresh Tokenâ”‚  â”‚-Advanced     â”‚  â”‚-Data Import      â”‚  â”‚
â”‚  â”‚-API Key      â”‚  â”‚Filter        â”‚  â”‚-Validation       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚-Statistics   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                                      â”‚Export Routes     â”‚  â”‚
â”‚                                      â”‚-CSV, Excel, JSON â”‚  â”‚
â”‚                                      â”‚-ZIP Archive      â”‚  â”‚
â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚     MIDDLEWARE (Auth, RateLimit, Error Handler)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                  â”‚
          MongoDB (27017)        Redis (6379)
          - candidates           - Cache
          - users                - Rate Limits
          - refreshtokens        - Sessions
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Python Selenium Scraper            â”‚
    â”‚ (Script_craw.py / Script-run(task-table).py) â”‚
    â”‚                                       â”‚
    â”‚  â€¢ Chrome WebDriver automation        â”‚
    â”‚  â€¢ LinkedIn login handling            â”‚
    â”‚  â€¢ Profile data extraction            â”‚
    â”‚  â€¢ Multi-threading support           â”‚
    â”‚  â€¢ Kafka producer integration        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

```
BACKEND:
â”œâ”€ Node.js 18+ (JavaScript runtime)
â”œâ”€ Express.js (REST API framework)
â”œâ”€ MongoDB 4.4+ (NoSQL Database)
â”œâ”€ Redis 6+ (Cache & Rate Limiting)
â”œâ”€ JWT (JSON Web Tokens)
â”œâ”€ bcryptjs (Password hashing)
â”œâ”€ Winston (Logging)
â”œâ”€ Mongoose (ODM)
â”œâ”€ Helmet (Security)
â”œâ”€ Multer (File upload)
â”œâ”€ ExcelJS (Excel export)
â””â”€ json2csv (CSV export)

SCRAPER:
â”œâ”€ Python 3.8+
â”œâ”€ Selenium (WebDriver)
â”œâ”€ BeautifulSoup4 (HTML parsing)
â”œâ”€ Kafka (Message queue)
â””â”€ Threading (Multi-threading)

INFRASTRUCTURE:
â”œâ”€ Docker & Docker Compose
â”œâ”€ Zookeeper (Kafka coordinator)
â”œâ”€ Kafka 7.3 (Message broker)
â””â”€ MongoDB 4.4 & Redis 7
```

---

## ğŸ”§ CÃ i Äáº·t & Khá»Ÿi Äá»™ng

### **Option 1: Docker Compose (Khuyáº¿n Nghá»‹)**

```bash
# Clone repository
git clone https://github.com/viet-du/Craw-linkedln-Back-end-basic-.git
cd Craw-linkedln-Back-end-basic-

# Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services
docker-compose up -d

# Xem logs
docker-compose logs -f app

# Dá»«ng toÃ n bá»™
docker-compose down
```

**Services sáº½ start:**
- MongoDB (27017)
- Redis (6379)
- Zookeeper (2181)
- Kafka (9092)
- Node.js Backend (3000)

### **Option 2: Local Development**

#### Step 1: Khá»Ÿi Ä‘á»™ng MongoDB & Redis
```bash
# MongoDB
docker run --name linkedin-mongodb -d -p 27017:27017 \
  -e MONGO_INITDB_ROOT_USERNAME=admin \
  -e MONGO_INITDB_ROOT_PASSWORD=admin123 \
  mongo:4.4

# Redis
docker run --name linkedin-redis -d -p 6379:6379 redis:7-alpine
```

#### Step 2: Setup Backend
```bash
cd backend
npm install
```

#### Step 3: Táº¡o `.env`
```bash
NODE_ENV=development
PORT=3000
BASE_URL=http://localhost:3000
MONGODB_URI=mongodb://admin:admin123@localhost:27017/linkedin_candidates?authSource=admin
REDIS_URL=redis://localhost:6379
JWT_SECRET=your_super_secret_jwt_key_min_32_chars_12345!@#$%
JWT_EXPIRES_IN=8h
REFRESH_TOKEN_EXPIRES_IN=30d
MAX_FILE_SIZE=10485760
UPLOAD_PATH=./uploads
LOG_LEVEL=debug
CORS_ORIGIN=http://localhost:3000
```

#### Step 4: Start Backend
```bash
npm run dev     # Development vá»›i auto-reload
npm start       # Production
npm run import  # Import demo data
```

#### Step 5: Access
```
Frontend:  http://localhost:3000
API:       http://localhost:3000/api
Health:    http://localhost:3000/health
API Docs:  http://localhost:3000/api-docs
```

### **Option 3: Cháº¡y Crawler (2 script riÃªng cho 2 má»¥c Ä‘Ã­ch)**

#### 1. Script cháº¡y bÃ¬nh thÆ°á»ng (thá»§ cÃ´ng, interactive)
File: `scraper/Script_craw.py`

- DÃ¹ng khi cáº§n cháº¡y thá»§ cÃ´ng.
- Script sáº½ há»i input trá»±c tiáº¿p trong lÃºc cháº¡y (thá»i gian lá»c, sá»‘ trang, sá»‘ profile...).

```bash
python scraper/Script_craw.py
```

#### 2. Script cÃ³ tham sá»‘ (dÃ nh cho cháº¡y tá»± Ä‘á»™ng)
File: `scraper/Script-run(task-table).py`

- DÃ¹ng cho Task Scheduler/cron/automation pipeline.
- KhÃ´ng cáº§n nháº­p tay náº¿u truyá»n tham sá»‘ Ä‘áº§y Ä‘á»§.

```bash
python "scraper/Script-run(task-table).py" --hours 24 --max-profiles 100 --pages 3
```

**Tham sá»‘ há»— trá»£:**
- `--hours`: lá»c profile theo sá»‘ giá» gáº§n nháº¥t
- `--max-profiles`: giá»›i háº¡n sá»‘ profile crawl tá»‘i Ä‘a
- `--pages`: sá»‘ trang káº¿t quáº£ cáº§n quÃ©t

#### 3. Scheduler láº·p lá»‹ch crawler (APScheduler)
File: `scraper/scheduler.py`

- Timezone: `Asia/Ho_Chi_Minh`
- Lá»‹ch hiá»‡n táº¡i: cháº¡y vÃ o `08:00`, `11:00`, `14:00`, `18:00` má»—i ngÃ y
- Job thá»±c thi: `run_crawler(hours=24, max_profiles=90, pages=4)`

Cháº¡y scheduler:

```bash
python scraper/scheduler.py
```

Sá»­a má»‘c giá» láº·p trong:

```python
trigger=CronTrigger(hour='8,11,14,18', minute=0)
```

VÃ­ dá»¥ Ä‘á»•i thÃ nh 2 láº§n/ngÃ y:

```python
trigger=CronTrigger(hour='9,21', minute=0)
```

Náº¿u muá»‘n láº·p theo chu ká»³ cá»‘ Ä‘á»‹nh (vd: má»—i 24 giá»), cÃ³ thá»ƒ dÃ¹ng trigger `interval` (máº«u Ä‘Ã£ Ä‘Æ°á»£c comment sáºµn trong file).

#### Kafka backup consumer (Ä‘i kÃ¨m crawler)
File: `scraper/kafka_consumer.py`

```bash
python scraper/kafka_consumer.py
```

Consumer sáº½ Ä‘á»c topic `linkedin-profiles` vÃ  backup theo ngÃ y vÃ o `Data/backup_data/profiles_YYYY-MM-DD.json`.

---

## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn Chi Tiáº¿t

```
linkedlin/
â”‚
â”œâ”€â”€ docker-compose.yml              â† Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services
â”œâ”€â”€ Dockerfile                      â† Build image Node.js
â”œâ”€â”€ mongo-init.js                   â† MongoDB init script (indexes, collections)
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ public/                     â† Frontend static files
â”‚   â”‚   â”œâ”€â”€ index.html              â† Trang chá»§
â”‚   â”‚   â”œâ”€â”€ login.html              â† ÄÄƒng nháº­p
â”‚   â”‚   â”œâ”€â”€ dashboard.html          â† Dashboard chÃ­nh
â”‚   â”‚   â”œâ”€â”€ admin.html              â† Quáº£n lÃ½ user
â”‚   â”‚   â”œâ”€â”€ authInterceptor.js      â† JWT HTTP interceptor
â”‚   â”‚   â””â”€â”€ js/
â”‚   â”‚       â””â”€â”€ chart.umd.min.js    â† Chart.js library
â”‚   â”‚
>>>>>>> f87fcc33870f50b93e656a90b8da6e68fde0f4dd
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ models/                 â† Mongoose Schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ Candidate.js        â† á»¨ng viÃªn: name, job, skills, exp, edu
â”‚   â”‚   â”‚   â”œâ”€â”€ User.js             â† NgÆ°á»i dÃ¹ng: username, role, password
â”‚   â”‚   â”‚   â””â”€â”€ RefreshToken.js     â† Refresh token: userId, expiresAt
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ routes/                 â† API Routes
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.js             â† Login, Register, Refresh, Logout
â”‚   â”‚   â”‚   â”œâ”€â”€ candidates.js       â† Search, Advanced Filter, Stats
â”‚   â”‚   â”‚   â”œâ”€â”€ admin.js            â† User Management, Import Data
â”‚   â”‚   â”‚   â””â”€â”€ export.js           â† CSV, Excel, JSON, ZIP Export
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ middleware/
<<<<<<< HEAD
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ scripts/importData.js
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”œâ”€â”€ server.js
â”‚   â”œâ”€â”€ server_local.js
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ Script_craw.py
â”‚   â”œâ”€â”€ Script-run(task-table).py
â”‚   â”œâ”€â”€ kafka_consumer.py
â”‚   â”œâ”€â”€ login.txt
â”‚   â””â”€â”€ profiles.txt
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ output.json
â”‚   â”œâ”€â”€ crawl_meta.json
â”‚   â””â”€â”€ backup_data/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ mongo-init.js
=======
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.js             â† JWT & API Key verification
â”‚   â”‚   â”‚   â”œâ”€â”€ rateLimit.js        â† Rate limiting per endpoint
â”‚   â”‚   â”‚   â””â”€â”€ errorHandler.js     â† Global error handling
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ logger.js           â† Winston logger (error, combined, audit)
â”‚   â”‚   â”‚   â”œâ”€â”€ redisClient.js      â† Redis wrapper (get, set, cache)
â”‚   â”‚   â”‚   â”œâ”€â”€ dataQuality.js      â† Validate & score data
â”‚   â”‚   â”‚   â””â”€â”€ adapter.js          â† Data transformation
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â”‚       â””â”€â”€ importData.js       â† Import candidates tá»« JSON
â”‚   â”‚
â”‚   â”œâ”€â”€ server.js                   â† Express app entry
â”‚   â”œâ”€â”€ server_local.js             â† Local dev config
â”‚   â”œâ”€â”€ package.json                â† Dependencies
â”‚   â”œâ”€â”€ logs/                       â† Log directory
â”‚   â””â”€â”€ uploads/                    â† Uploaded files
â”‚
â”œâ”€â”€ scraper/                        â† Python Selenium Crawler
â”‚   â”œâ”€â”€ Script_craw.py                â† Crawler cháº¡y thÆ°á»ng (interactive)
â”‚   â”œâ”€â”€ Script-run(task-table).py     â† Crawler cÃ³ tham sá»‘ (automation)
â”‚   â”œâ”€â”€ kafka_consumer.py           â† Kafka consumer
â”‚   â”œâ”€â”€ login.txt                   â† LinkedIn credentials
â”‚   â”œâ”€â”€ profiles.txt                â† Profile URLs (má»™t URL/dÃ²ng)
â”‚   â””â”€â”€ test-kafka.py               â† Test Kafka
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ output.json                 â† Crawled data
â”‚   â”œâ”€â”€ crawl_meta.json             â† Metadata (last_crawled, checksum)
â”‚   â””â”€â”€ backup_data/                â† Backups
â”‚
â””â”€â”€ logs/                           â† Application logs
    â”œâ”€â”€ error.log                   â† Errors
    â”œâ”€â”€ combined.log                â† All logs
    â”œâ”€â”€ audit.log                   â† Audit trail
    â””â”€â”€ http.log                    â† HTTP requests
>>>>>>> f87fcc33870f50b93e656a90b8da6e68fde0f4dd
```

---

<<<<<<< HEAD
## YÃªu cáº§u mÃ´i trÆ°á»ng

- Node.js >= 18
- npm >= 9
- Python >= 3.8
- Docker + Docker Compose (khuyáº¿n nghá»‹)
- Chrome + ChromeDriver (cho Selenium)

Python package chÃ­nh:

- `selenium`
- `beautifulsoup4`
- `kafka-python`

---

## Cháº¡y nhanh báº±ng Docker Compose (khuyáº¿n nghá»‹)

```bash
docker-compose up -d
docker-compose ps
docker-compose logs -f app
```

CÃ¡c service:

- Backend: `http://localhost:3000`
- MongoDB: `localhost:27017`
- Redis: `localhost:6379`
- Kafka: `localhost:9092`

Dá»«ng:

```bash
docker-compose down
docker-compose down -v
```

---

## Cháº¡y backend local

### 1) Cáº¥u hÃ¬nh `.env`

Táº¡o file `backend/.env`:

```env
NODE_ENV=development
PORT=3000
MONGODB_URI=mongodb://admin:admin123@localhost:27017/linkedin_candidates?authSource=admin
REDIS_URL=redis://localhost:6379
REDIS_TTL=3600
JWT_SECRET=your_super_secret_min_32_chars
JWT_EXPIRES_IN=8h
MAX_FILE_SIZE=10485760
UPLOAD_PATH=./uploads
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123
ADMIN_EMAIL=admin@example.com
=======
## ğŸ“š Giáº£i ThÃ­ch Tá»«ng File

### **Models** (`backend/src/models/`)

#### **Candidate.js**
```javascript
{
  // Basic Info
  name: String,                              // TÃªn á»©ng viÃªn (text indexed)
  location: String,                          // Vá»‹ trÃ­ (vÃ­ dá»¥: Ho Chi Minh City)
  job_title: String,                         // Chá»©c vá»¥ hiá»‡n táº¡i (text indexed)
  
  // URLs
  linkedin_url: String (unique),             // https://linkedin.com/in/...
  normalized_url: String (unique),           // Chuáº©n hÃ³a URL
  
  // Experience & Skills
  total_experience_count: Number,            // Tá»•ng sá»‘ nÄƒm
  experience: [{
    position: String,                        // VÃ­ dá»¥: "Software Engineer"
    company: String,                         // VÃ­ dá»¥: "Google"
    employment_type: String,                 // Full-time, Part-time, etc.
    duration: String,                        // "Sep 2023 - Jan 2024"
    duration_months: Number                  // 4
  }],
  
  skills: [String],                          // ["Python", "JavaScript", ...]
  
  // Education
  education: [{
    school: String,                          // VÃ­ dá»¥: "Harvard University"
    degree: String,                          // "Bachelor of Science"
    degree_level: String,                    // Bachelor, Master, PhD, etc.
    duration: String                         // "2020 - 2024"
  }],
  
  // Scoring
  score: Number (0-100),                     // Äiá»ƒm Ä‘Ã¡nh giÃ¡
  data_quality_score: Number (0-100),        // Äiá»ƒm cháº¥t lÆ°á»£ng dá»¯ liá»‡u
  status: String enum('active', 'inactive', 'flagged'),
  
  // Timestamps
  crawled_at: Date,                          // Crawl time
  updated_at: Date,                          // Last update
  createdAt: Date, updatedAt: Date
}
```

**Quality Score (tÃ­nh tá»± Ä‘á»™ng):**
- name + job_title: 40 points
- experience: 25 points
- education: 15 points
- skills: 10 points
- linkedin_url: 10 points

---

#### **User.js**
```javascript
{
  username: String (unique),                 // 3-30 chars, alphanumeric + _
  passwordHash: String,                      // bcrypt hashed password
  email: String (unique, optional),
  role: String enum('user', 'admin'),        // PhÃ¢n quyá»n
  
  // Account Security
  isActive: Boolean,                         // TÃ i khoáº£n hoáº¡t Ä‘á»™ng?
  lastLogin: Date,                           // Láº§n login gáº§n nháº¥t
  loginAttempts: Number,                     // Failed login counter
  lockUntil: Date,                           // Lock account until this date
  
  // API Access
  apiKey: String (unique),                   // Auto-generated for admin
  
  // Preferences
  preferences: {
    theme: String enum('light', 'dark', 'auto'),
    itemsPerPage: Number (default: 20)
  },
  
  createdAt: Date, updatedAt: Date
}
```

**Login Lock Logic:**
- 5 failed logins â†’ lock 2 hours
- Successful login â†’ reset counter

---

#### **RefreshToken.js**
```javascript
{
  token: String (unique),                    // JWT token (hashed)
  userId: ObjectId (indexed),                // Reference to User
  expiresAt: Date,                           // 7 ngÃ y tá»« lÃºc create
  revoked: Boolean,                          // Bá»‹ thu há»“i?
  replacedByToken: String,                   // Token thay tháº¿ (khi rotate)
  deviceInfo: String,                        // User-Agent (tracking device)
  createdAt: Date
}
```

**TTL Index:** MongoDB tá»± Ä‘á»™ng xoÃ¡ khi `expiresAt` háº¿t háº¡n

---

### **Routes** (`backend/src/routes/`)

#### **auth.js - Authentication**

```javascript
POST /api/auth/login
{
  "username": "admin",
  "password": "password123"
}
Response:
{
  "success": true,
  "data": {
    "user": { "id": "...", "username": "admin", "role": "admin" },
    "tokens": {
      "accessToken": "eyJhbGc...",      // 8 hours
      "refreshToken": "eyJhbGc...",     // 7 days
      "expiresIn": 28800
    }
  }
}

POST /api/auth/register
{
  "username": "newuser",
  "password": "password123",
  "email": "user@example.com"
}

POST /api/auth/refresh
{
  "refreshToken": "eyJhbGc..."
}
Response: { "accessToken": "..." }

POST /api/auth/logout
{
  "refreshToken": "eyJhbGc..."
}

GET /api/auth/me
Headers: Authorization: Bearer {token}
Response: { "success": true, "data": {...user} }
```

#### **candidates.js - Data Management**

```javascript
GET /api/candidates/statistics/summary
Response:
{
  "success": true,
  "data": {
    "totalCandidates": 500,
    "avgExperience": 5.2,
    "avgScore": 78.5,
    "avgQuality": 85.3
  }
}

GET /api/candidates/statistics/distributions?type=skills&limit=10
Response:
{
  "success": true,
  "data": [
    { "label": "Python", "count": 150, "percentage": 30 },
    { "label": "JavaScript", "count": 120, "percentage": 24 },
    ...
  ]
}

GET /api/candidates/search?q=python&page=1&limit=20
Response:
{
  "success": true,
  "data": [{...candidates}, ...],
  "pagination": { "page": 1, "total": 150, "pages": 8, ... }
}

GET /api/candidates/advanced-search
?q=senior&minExperience=5&maxExperience=10
&skills=Python,JavaScript&location=Ho%20Chi%20Minh
Response: { "success": true, "data": [...], "pagination": {...} }

GET /api/candidates/:id
Response: { "success": true, "data": {...full candidate} }

POST /api/candidates
Body: { candidate object }
Response: { "success": true, "data": {...created candidate} }
```

#### **admin.js - Admin Management**

```javascript
GET /api/admin/users
Response:
{
  "success": true,
  "data": [
    {
      "id": "...",
      "username": "admin",
      "email": "admin@example.com",
      "role": "admin",
      "isActive": true,
      "lastLogin": "2026-02-19T10:30:00Z",
      "createdAt": "2026-01-01T00:00:00Z"
    },
    ...
  ]
}

POST /api/admin/users
Body:
{
  "username": "newuser",
  "password": "password123",
  "email": "newuser@example.com",
  "role": "user"
}

PUT /api/admin/users/{id}
Body:
{
  "email": "newemail@example.com",
  "role": "admin",
  "isActive": true
}

DELETE /api/admin/users/{id}
Response: { "success": true, "message": "User deleted" }

POST /api/admin/import
(multipart/form-data with JSON file)
Response:
{
  "success": true,
  "message": "Imported 500 candidates",
  "stats": {
    "total": 500,
    "imported": 500,
    "updated": 0,
    "skipped": 0,
    "errors": 0
  }
}
```

#### **export.js - Data Export**

```javascript
GET /api/export/csv?limit=1000
Response: CSV file download

GET /api/export/excel?limit=1000
Response: Excel file download

GET /api/export/json?limit=1000
Response: JSON file download

GET /api/export/zip?format=all
Response: ZIP file (chá»©a CSV, Excel, JSON)
```

---

## ğŸ“Š Database Schema Chi Tiáº¿t

### MongoDB Collections

#### **candidates** Collection
```javascript
db.candidates.find().select({
  _id: 1,
  name: 1,
  job_title: 1,
  location: 1,
  skills: 1,
  score: 1,
  data_quality_score: 1
})

// Indexes
db.candidates.getIndexes()
// Result:
[
  { key: { _id: 1 } },                          // Default
  { key: { name: 1 } },
  { key: { job_title: 1 } },
  { key: { linkedin_url: 1 }, unique: true },
  { key: { normalized_url: 1 }, unique: true },
  { key: { score: -1 } },
  { key: { total_experience_count: -1 } },
  { key: { location: 1 } },
  { key: { skills: 1 } },
  { key: { 'education.degree_level': 1 } },
  { key: { status: 1 } },
  { 
    key: { name: 'text', job_title: 'text', ... },  // Text search index
    weights: { name: 10, job_title: 5, ... }
  }
]
```

#### **users** Collection
```javascript
db.users.findOne({ username: "admin" })
// Result:
{
  _id: ObjectId("507f1f77bcf86cd799439011"),
  username: "admin",
  passwordHash: "$2a$12$...",
  role: "admin",
  email: "admin@example.com",
  isActive: true,
  lastLogin: ISODate("2026-02-19T10:30:00Z"),
  loginAttempts: 0,
  lockUntil: null,
  apiKey: "abc123def456...",
  preferences: {
    theme: "light",
    itemsPerPage: 20
  },
  createdAt: ISODate("2026-01-01T00:00:00Z"),
  updatedAt: ISODate("2026-02-19T10:30:00Z")
}
```

#### **refreshtokens** Collection
```javascript
db.refreshtokens.findOne({ userId: ObjectId("...") })
// Result:
{
  _id: ObjectId("..."),
  token: "e3b0c44298fc1c14...",     // Hash of JWT
  userId: ObjectId("507f1f77bcf86cd799439011"),
  expiresAt: ISODate("2026-02-26T00:00:00Z"),     // 7 days
  revoked: false,
  replacedByToken: null,
  deviceInfo: "Mozilla/5.0...",
  createdAt: ISODate("2026-02-19T00:00:00Z")
}
```

---

## ğŸ” CÃ¡c Lá»‡nh Kiá»ƒm Tra Data

### MongoDB Commands

```bash
# Káº¿t ná»‘i MongoDB
mongosh -u admin -p admin123 --authenticationDatabase admin

# Chá»n database
use linkedin_candidates

# Kiá»ƒm tra táº­p há»£p
show collections                                    # Liá»‡t kÃª collections
db.candidates.countDocuments()                      # Tá»•ng sá»‘ candidates
db.users.countDocuments()                           # Tá»•ng sá»‘ users

# Xem dá»¯ liá»‡u
db.candidates.findOne()                             # Xem 1 candidate
db.candidates.find().limit(5).pretty()              # Top 5
db.users.find().pretty()                            # All users
db.refreshtokens.find().limit(3).pretty()           # Refresh tokens

# Statistics
db.candidates.aggregate([
  { $group: {
      _id: null,
      count: { $sum: 1 },
      avgScore: { $avg: '$score' },
      avgQuality: { $avg: '$data_quality_score' },
      minExp: { $min: '$total_experience_count' },
      maxExp: { $max: '$total_experience_count' }
    }
  }
])

# TÃ¬m kiáº¿m
db.candidates.find({ job_title: /engineer/i })      # Regex search
db.candidates.find({ skills: "Python" })            # By skill
db.candidates.find({ location: "Ho Chi Minh" })     # By location

# Cáº­p nháº­t
db.candidates.updateOne(
  { _id: ObjectId("...") },
  { $set: { status: "active" } }
)

# XoÃ¡
db.candidates.deleteOne({ _id: ObjectId("...") })
```

### Redis Commands

```bash
# Káº¿t ná»‘i Redis
redis-cli

# Kiá»ƒm tra toÃ n bá»™
INFO                                                # Server info
DBSIZE                                              # Tá»•ng sá»‘ key

# Cache operations
GET candidates:page:1                               # Get cache key
DEL candidates:page:1                               # Delete cache key
KEYS "candidates:*"                                 # Find all cache keys

# Rate limiting
GET rate_limit:user_id:search                       # Check rate limit
INCR rate_limit:user_id:search                      # Increment counter

# Session tracking
GET blacklist:token_jwt_here                        # Check token blacklist
TTL blacklist:token_jwt_here                        # Time to live

# Utility
FLUSHALL                                            # Clear all (âš ï¸)
CONFIG GET maxmemory                                # Memory settings
```

### API Endpoints for Testing

```bash
# Health check
curl http://localhost:3000/health

# Login
curl -X POST http://localhost:3000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username":"admin","password":"password123"}'

# Search candidates
curl -H "Authorization: Bearer {token}" \
  "http://localhost:3000/api/candidates/search?q=python"

# Export data
curl -H "Authorization: Bearer {token}" \
  "http://localhost:3000/api/export/csv" > candidates.csv

# Admin info
curl -H "Authorization: Bearer {token}" \
  http://localhost:3000/api/admin/users
>>>>>>> f87fcc33870f50b93e656a90b8da6e68fde0f4dd
```

### 2) CÃ i vÃ  cháº¡y

<<<<<<< HEAD
```bash
cd backend
npm install
npm run dev
```

Endpoints nhanh:

- `GET /health`
- `GET /api-docs`
- UI: `http://localhost:3000/`

---

## Crawler: 2 script Ä‘Ãºng má»¥c Ä‘Ã­ch

Trong project cÃ³ **2 script crawler chÃ­nh** nhÆ° báº¡n nÃ³i:

### 1) Script cháº¡y bÃ¬nh thÆ°á»ng (interactive)

File: `scraper/Script_craw.py`

- Cháº¡y thá»§ cÃ´ng, há»i input trong lÃºc cháº¡y (thá»i gian lá»c, sá»‘ trang, sá»‘ profile...).
- PhÃ¹ há»£p khi test nhanh hoáº·c váº­n hÃ nh thá»§ cÃ´ng.

Cháº¡y:

```bash
python scraper/Script_craw.py
```

### 2) Script cÃ³ tham sá»‘ (dÃ nh cho cháº¡y tá»± Ä‘á»™ng)

File: `scraper/Script-run(task-table).py`

- Há»— trá»£ tham sá»‘ CLI Ä‘á»ƒ tÃ­ch há»£p Task Scheduler/cron/CI.
- DÃ¹ng khi muá»‘n automation á»•n Ä‘á»‹nh, khÃ´ng nháº­p tay.

VÃ­ dá»¥:

```bash
python "scraper/Script-run(task-table).py" --hours 24 --max-profiles 100 --pages 3
```

Tham sá»‘:

- `--hours`: lá»c profile theo sá»‘ giá» gáº§n nháº¥t.
- `--max-profiles`: giá»›i háº¡n sá»‘ profile crawl tá»‘i Ä‘a.
- `--pages`: sá»‘ trang káº¿t quáº£ cáº§n quÃ©t.
=======
## ğŸ“ File Data & Tráº¡ng ThÃ¡i

### **Data/output.json** - Dá»¯ Liá»‡u Crawl
```json
[
  {
    "name": "Luong Thanh",
    "location": "Ho Chi Minh City, Vietnam",
    "job_title": "Software Engineer | DevOps",
    "education": [
      {
        "school": "VNUHCM - University of Science",
        "degree": "Bachelor's degree, Data Science",
        "duration": "Aug 2022 - Jul 2026"
      }
    ],
    "experience": [
      {
        "position": "System Engineer",
        "company": "Zalo",
        "employment_type": "Full-time",
        "duration": "Sep 2025 - Present"
      }
    ],
    "total_experience_count": 3,
    "url": "https://www.linkedin.com/in/luongthanh/"
  },
  ...
]
```

**Tráº¡ng thÃ¡i dá»¯ liá»‡u:**
- `active` - á»¨ng viÃªn Ä‘ang hoáº¡t Ä‘á»™ng (máº·c Ä‘á»‹nh)
- `inactive` - KhÃ´ng cÃ²n hoáº¡y Ä‘á»™ng
- `flagged` - Dá»¯ liá»‡u Ä‘Ã¡ng ngá»

### **Data/crawl_meta.json** - Metadata Crawl
```json
{
  "https://www.linkedin.com/in/luongthanh/": {
    "last_crawled": "2026-02-19T22:05:46.344312",
    "checksum": "8ca2098381a2ec8b955150a631e79afade320dcaf38e825a332cd3af78145b42"
  },
  "https://www.linkedin.com/in/nguyen-ho-thien-thanh/": {
    "last_crawled": "2026-02-19T22:05:48.360992",
    "checksum": "8ca2098381a2ec8b955150a631e79afade320dcaf38e825a332cd3af78145b42"
  }
}
```

**ThÃ´ng tin:**
- `last_crawled` - Láº§n crawl gáº§n nháº¥t
- `checksum` - Äá»ƒ detect changes (unchanged = same hash)

### **Logs/** - Application Logs

```
logs/
â”œâ”€â”€ error.log         â† Chi cÃ³ errors (level: error)
â”‚   [2026-02-19 10:30:00] ERROR: MongoDB connection failed
â”‚   [2026-02-19 10:31:00] ERROR: ValidationError: Name required
â”‚
â”œâ”€â”€ combined.log      â† Táº¥t cáº£ logs (info, warn, error, etc.)
â”‚   [2026-02-19 10:00:00] INFO: Server started on port 3000
â”‚   [2026-02-19 10:01:00] WARN: Redis not available
â”‚   [2026-02-19 10:30:00] ERROR: Database error
â”‚
â”œâ”€â”€ audit.log         â† Security events
â”‚   { "level": "audit", "message": "Login", "userId": "507f...", "ip": "192.168.1.1", "timestamp": "2026-02-19T10:00:00Z" }
â”‚   { "level": "audit", "message": "User created", "adminId": "507f...", "newUserId": "...", "timestamp": "..." }
â”‚   { "level": "audit", "message": "CSV export", "userId": "507f...", "count": 500, "timestamp": "..." }
â”‚
â””â”€â”€ http.log          â† HTTP requests
    { "method": "GET", "url": "/api/candidates/search", "statusCode": 200, "duration": 45, "userId": "507f..." }
    { "method": "POST", "url": "/api/auth/login", "statusCode": 200, "duration": 120 }
```

### **Rating & Quality Scores**

#### **score** (0-100) - Äiá»ƒm á»¨ng ViÃªn
```
Phá»¥ thuá»™c vÃ o:
- Experience (max 40): years * 4
- Education (max 30): dá»±a trÃªn degree level
  - PhD: 30
  - Master/MBA: 25
  - Bachelor: 15
  - High School: 5
- Experience entries (max 20): sá»‘ láº§n * 2
- Skills (max 10): tháº¥p nháº¥t lÃ  0, max lÃ  10

VÃ­ dá»¥:
- 5 years exp (20) + Bachelor (15) + 2 jobs (4) + 5 skills (2.5) = ~42/100
- 10 years exp (40) + Master (25) + 5 jobs (10) + 15 skills (10) = ~85/100
```

#### **data_quality_score** (0-100) - Äiá»ƒm Cháº¥t LÆ°á»£ng Dá»¯ Liá»‡u
```
TÃ­nh toÃ¡n:
- name + job_title (present): 40%
- linkedin_url (present): 10%
- experience (count * 5, max 25%): 0-25%
- education (count * 5, max 15%): 0-15%
- skills (count * 2, max 10%): 0-10%

VÃ­ dá»¥:
- Chá»‰ cÃ³ name + job_title: 40%
- + LinkedIn URL: 50%
- + 1 experience: 55%
- + 1 education: 60%
- + 3 skills: 66%
```
>>>>>>> f87fcc33870f50b93e656a90b8da6e68fde0f4dd

---

## Láº·p lá»‹ch crawler (scheduler)

File: `scraper/scheduler.py`

- DÃ¹ng `APScheduler` vá»›i timezone `Asia/Ho_Chi_Minh`.
- Job hiá»‡n táº¡i Ä‘ang cháº¡y theo cron táº¡i cÃ¡c má»‘c: `08:00`, `11:00`, `14:00`, `18:00` má»—i ngÃ y.
- Job gá»i hÃ m crawl vá»›i tham sá»‘: `run_crawler(hours=24, max_profiles=90, pages=4)`.

Cháº¡y scheduler:

<<<<<<< HEAD
```bash
python scraper/scheduler.py
```

Náº¿u muá»‘n Ä‘á»•i má»‘c giá» láº·p, sá»­a dÃ²ng:

```python
trigger=CronTrigger(hour='8,11,14,18', minute=0)
```

VÃ­ dá»¥ chá»‰ cháº¡y 2 láº§n/ngÃ y:

```python
trigger=CronTrigger(hour='9,21', minute=0)
```

Náº¿u muá»‘n cháº¡y theo chu ká»³ cá»‘ Ä‘á»‹nh (vÃ­ dá»¥ má»—i 24 giá») thay vÃ¬ theo giá» cá»‘ Ä‘á»‹nh trong ngÃ y, dÃ¹ng job `interval` (Ä‘Ã£ cÃ³ máº«u comment trong file).

---

## Kafka backup consumer

File: `scraper/kafka_consumer.py`

- Consume topic `linkedin-profiles`.
- Backup theo ngÃ y vÃ o `Data/backup_data/profiles_YYYY-MM-DD.json`.

Cháº¡y:

```bash
python scraper/kafka_consumer.py
```

---

## Import dá»¯ liá»‡u vÃ o MongoDB

Tá»« backend:

```bash
cd backend
npm run import
```

Script import cho phÃ©p:

- Upsert (cáº­p nháº­t náº¿u tá»“n táº¡i)
- Insert only (bá» qua báº£n ghi Ä‘Ã£ cÃ³)
- Replace all (xÃ³a cÅ© rá»“i import láº¡i)
=======
### **MongoDB Connection Failed**

```bash
# Check if MongoDB is running
docker ps | grep mongodb

# If not running
docker run -d --name linkedin-mongodb \
  -e MONGO_INITDB_ROOT_USERNAME=admin \
  -e MONGO_INITDB_ROOT_PASSWORD=admin123 \
  -p 27017:27017 \
  mongo:4.4

# Test connection
mongosh -u admin -p admin123 --authenticationDatabase admin
```

### **Redis Connection Failed**

```bash
# Check Redis
docker ps | grep redis

# If not running
docker run -d --name linkedin-redis -p 6379:6379 redis:7-alpine

# Test
redis-cli ping
# Should return: PONG
```

### **Rate Limit Exceeded**

```bash
# Clear rate limits in Redis
redis-cli
KEYS "rate_limit:*"
DEL rate_limit:user_id:endpoint

# Or login with admin (no rate limit)
```

### **JWT Token Expired**

```bash
# Use refresh endpoint
POST /api/auth/refresh
{
  "refreshToken": "your_refresh_token"
}

# Get new access token
```

### **Port Already in Use**

```bash
# Find process using port 3000
lsof -i :3000

# Kill process
kill -9 <PID>

# Or use different port
PORT=3001 npm run dev
```

### **Data Quality Validation Fails**

```bash
# Check error logs
tail -f logs/error.log

# Validate individual profile
curl -X POST http://localhost:3000/api/candidates/validate \
  -H "Authorization: Bearer {token}" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "John Doe",
    "job_title": "Engineer",
    "linkedin_url": "https://linkedin.com/in/john-doe",
    ...
  }'
```
>>>>>>> f87fcc33870f50b93e656a90b8da6e68fde0f4dd

---

## API chÃ­nh

<<<<<<< HEAD
### Auth

- `POST /api/auth/login`
- `POST /api/auth/register`
- `POST /api/auth/refresh`
- `POST /api/auth/logout`
- `GET /api/auth/me`

### Candidates

- `GET /api/candidates`
- `GET /api/candidates/search?q=...`
- `GET /api/candidates/advanced-search?...`
- `GET /api/candidates/statistics/summary`
- `GET /api/candidates/statistics/distributions?type=job_title|skills|location|education_level`
- `GET /api/candidates/top/experience`
- `GET /api/candidates/top/education`
- `POST /api/candidates`
- `PUT /api/candidates/:id`
- `DELETE /api/candidates/:id`
- `POST /api/candidates/validate`
- `POST /api/candidates/batch-validate`

### Admin

- `GET /api/admin/users`
- `POST /api/admin/users`
- `PUT /api/admin/users/:id`
- `DELETE /api/admin/users/:id`
- `POST /api/admin/import`
- `DELETE /api/admin/batch`
- `PATCH /api/admin/batch`
- `GET /api/admin/export`
- `GET /api/admin/statistics`
- `POST /api/admin/clear-cache`
- `GET /api/admin/data-quality-report`

### Export

- `GET /api/export/csv`
- `GET /api/export/excel`
- `GET /api/export/json`
- `GET /api/export/with-photos` (admin)
- `GET /api/export/bulk` (admin)

---

## Báº£o máº­t vÃ  lÆ°u Ã½

- KhÃ´ng commit `scraper/login.txt` (chá»©a credential tháº­t).
- Äá»•i ngay tÃ i khoáº£n admin máº·c Ä‘á»‹nh trÆ°á»›c khi triá»ƒn khai tháº­t.
- Cáº¥u hÃ¬nh `JWT_SECRET` máº¡nh.
- TuÃ¢n thá»§ chÃ­nh sÃ¡ch sá»­ dá»¥ng dá»¯ liá»‡u vÃ  Ä‘iá»u khoáº£n LinkedIn.

---

## Troubleshooting nhanh

- Backend khÃ´ng lÃªn:
- Kiá»ƒm tra `MONGODB_URI`, `REDIS_URL`, `JWT_SECRET` trong `.env`.
- Xem log táº¡i `backend/logs/`.

- Token háº¿t háº¡n:
- Gá»i `POST /api/auth/refresh` vá»›i refresh token.

- Crawler lá»—i:
- Kiá»ƒm tra Chrome/ChromeDriver tÆ°Æ¡ng thÃ­ch.
- Kiá»ƒm tra Kafka Ä‘ang cháº¡y táº¡i `localhost:9092`.

---

## License

MIT
=======
- **Index:** Táº¡o index cho fields Ä‘Æ°á»£c tÃ¬m kiáº¿m thÆ°á»ng xuyÃªn
- **Caching:** Redis cache frequently accessed data
- **Lean Queries:** DÃ¹ng `.lean()` cho read-only queries
- **Pagination:** LuÃ´n paginate káº¿t quáº£ (default 20/page)
- **Rate Limiting:** Báº£o vá»‡ API khá»i abuse
- **Gzip:** Enable compression (Helmet)
- **Monitoring:** Theo dÃµi slow queries, memory usage

---

## ğŸ” Security Notes

- âœ… Password hashed vá»›i bcryptjs (12 rounds)
- âœ… JWT tokens signed vá»›i secret key
- âœ… Refresh tokens hashed trong DB
- âœ… Rate limiting (IP + User ID)
- âœ… CORS enabled (configurable)
- âœ… Helmet security headers
- âœ… MongoDB sanitization
- âœ… Audit logging táº¥t cáº£ sensitive actions
- âœ… Account locking sau failed logins
- âœ… Token blacklist (Redis)

---

## ğŸ“ Support & Feedback

**Author:** DÆ° Quá»‘c Viá»‡t  
**GitHub:** [viet-du/Craw-linkedln-Back-end-basic-](https://github.com/viet-du/Craw-linkedln-Back-end-basic-)

---

**Last Updated:** February 19, 2026  
**Version:** 1.1.0  
**Status:** âœ… Production Ready
>>>>>>> f87fcc33870f50b93e656a90b8da6e68fde0f4dd
