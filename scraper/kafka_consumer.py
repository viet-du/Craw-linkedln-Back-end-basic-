import json
import os
from kafka import KafkaConsumer
from datetime import datetime
import threading
import signal
import sys


# Cáº¥u hÃ¬nh Kafka
KAFKA_BROKER = 'localhost:9092'
TOPIC = 'linkedin-profiles'
BACKUP_DIR = 'backup_data'  # ThÆ° má»¥c lÆ°u file JSON backup

# Táº¡o thÆ° má»¥c backup náº¿u chÆ°a tá»“n táº¡i
os.makedirs(BACKUP_DIR, exist_ok=True)

# Biáº¿n toÃ n cá»¥c Ä‘á»ƒ dá»«ng consumer
running = True

def signal_handler(sig, frame):
    global running
    print("\nğŸ›‘ Äang dá»«ng consumer...")
    running = False
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)

def get_backup_filename():
    """Táº¡o tÃªn file backup dá»±a trÃªn ngÃ y hiá»‡n táº¡i"""
    today = datetime.now().strftime('%Y-%m-%d')
    return os.path.join(BACKUP_DIR, f'profiles_{today}.json')

def write_to_json(data):
    """Ghi má»™t profile vÃ o file JSON (append)"""
    filename = get_backup_filename()
    # Náº¿u file chÆ°a tá»“n táº¡i, ghi máº£ng má»›i
    if not os.path.exists(filename):
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump([data], f, ensure_ascii=False, indent=2)
    else:
        # Äá»c file hiá»‡n táº¡i, append, ghi láº¡i
        with open(filename, 'r+', encoding='utf-8') as f:
            try:
                existing = json.load(f)
            except json.JSONDecodeError:
                existing = []
            existing.append(data)
            f.seek(0)
            json.dump(existing, f, ensure_ascii=False, indent=2)
            f.truncate()

def consume_messages():
    """Consumer chÃ­nh, láº¯ng nghe Kafka vÃ  ghi vÃ o file"""
    consumer = KafkaConsumer(
        TOPIC,
        bootstrap_servers=KAFKA_BROKER,
        value_deserializer=lambda m: json.loads(m.decode('utf-8')),
        auto_offset_reset='earliest',  # Äá»c tá»« Ä‘áº§u náº¿u chÆ°a cÃ³ offset
        enable_auto_commit=True,
        group_id='linkedin-backup-group',
        max_poll_records=100  # Láº¥y tá»‘i Ä‘a 100 message má»—i láº§n poll
    )
    
    print(f"âœ… Kafka consumer started. Listening to topic '{TOPIC}'")
    print(f"ğŸ“ Backup files will be saved in '{BACKUP_DIR}/'")
    
    batch = []
    last_commit_time = datetime.now()
    
    for message in consumer:
        if not running:
            break
        
        profile = message.value
        batch.append(profile)
        print(f"ğŸ“¥ Received: {profile.get('name', 'Unknown')} (offset {message.offset})")
        
        # Cá»© 10 message hoáº·c sau 10 giÃ¢y thÃ¬ ghi batch
        if len(batch) >= 10 or (datetime.now() - last_commit_time).seconds >= 10:
            for p in batch:
                write_to_json(p)
            print(f"ğŸ’¾ Saved {len(batch)} profiles to backup file")
            batch = []
            last_commit_time = datetime.now()
    
    # Ghi ná»‘t nhá»¯ng message cÃ²n láº¡i khi dá»«ng
    if batch:
        for p in batch:
            write_to_json(p)
        print(f"ğŸ’¾ Saved final {len(batch)} profiles")
    
    consumer.close()
    print("âœ… Consumer stopped.")

if __name__ == "__main__":
    try:
        consume_messages()
    except KeyboardInterrupt:
        print("\nğŸ›‘ Stopped by user")
    except Exception as e:
        print(f"âŒ Error: {e}")